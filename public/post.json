[
    
        
            {
                "ref": "https://yinminghao.top/post/fabric%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%9E%B6%E6%9E%84%E5%88%86%E6%9E%90.html",
                "title": "Fabric介绍与架构分析",
                "section": "post",
                "date" : "2020.08.03",
                "body": " 本文主要为官方文档与论文Hyperledger Fabric: A Distributed Operating System for Permissioned Blockchains的阅读记录, 包含 fabric 的介绍、模块划分、设计思想等\n 摘要 fabric: 可扩展区块链系统1. 模块化共识: 允许系统根据特定的场景和信任模型定制共识协议 2. 通用编程语言开发分布式应用: js、golang 等， 无需依赖加密货币 3. 可移植的身份管理实现许可模型\n传统区块链介绍 区块链又可以叫做不变账本。 在区块链网络里，互相不信任的节点分别维护账本的复制集，并执行共识协议验证交易、打包成区块，根据块 hash 构建区块链。任意节点可以无需身份证明的加入到公链(例如比特币、以太坊等)网络中，这些节点之间通常采用工作量证明(POW)。\n智能合约 区块链可以执行任意的、可编程的行为逻辑，这被称为智能合约。其实现方法与传统的状态机复制(SMR)类似，但与传统的状态机复制(SMR)不同的是: 1. 多个分布式应用(智能合约)同时运行 2. 应用(智能合约)可以被任何人动态部署 3. 应用(智能合约)是不可信的，甚至是恶意的\n许多公链(例如以太坊)采用主动复制的方式来实现智能合约，又被称为排序执行架构(order-execute architecture)，: 1. 共识或原子广播协议对事务进行排序，然后将其广播到所有节点 2. 每个节点按顺序执行事务,在这里所有事务都是确定的\n这种智能合约实现方式存在一些局限: 1. 共识协议被硬编码在区块链系统中，但是众所周知，没有一个普适的共识协议 2. 事务的信任模型由区块链硬编码的共识决定而不是由智能合约来决定 3. 智能合约必须以特定的语言(solidity\u0026hellip;)编写，这不易推广且可能出错 4. 由于事务需要被所有节点执行，这影响了区块链的性能 5. 由于智能合约的不可信，区块链必须采用一定措施(以太坊gas, EVM为没步低级操作设置gas消耗等)来避免被攻击: 考虑攻击者在智能合约里面写了死循环 6. 编程很难保证所有事务是确定的 7. 智能合约在所有节点之间运行，这无法保证私密性\nfabric Fabric(需权限许可的区块链) 与公链不同，网络中成员必须是已知的、具有身份证明的节点，这些节点为了同样的目标但彼此之间互相不完全信任: 例如商品、货物不同环节的经销商之间。 这些具有身份信息的节点之间通常采用拜占庭共识(BFT)。\n体系架构 fabric提出了具有弹性，灵活性，可扩展性和机密性的新区块链架构，支持使用通用编程语言编写分布式应用； fabric 遵从了执行-排序-确认的理念来在不受信任的环境中分布式执行不受信任的代码。与传统区块链将事务在全网执行不同，fabric 将事务执行分为三步：1. 验证事务正确性并执行事务，同时为事务进行背书(传统区块链的交易验证概念) 2. 通过共识对事务进行排序(无需执行事务，因此与事务本身无关) 3. 每个应用有不同的信任验证，避免并发带来的竞争\nfabric 体系结构的创新在于其在拜占庭、执行-排序-确认模式中采用主动和被动两种复制方式：1. 被动复制: 事务在部分节点(背书节点)之间执行, 允许并行执行、解决不确定性。背书策略等可灵活的被智能合约设定 2. 主动复制: 在排序之后，节点通过主动复制的方式进行账本更新，\n应用/事务执行 fabric 的分布式应用实现有两个部分构成1. 智能合约，chaincode(链码): 实现应用程序逻辑并在执行阶段运行的程序代码。chaincode是 fabric 分布式应用的核心，包含系统链码和应用链码两种，作用与应用的执行阶段，可以由不信任的开发人员编写 2. 背书策略: 作用域智能合约的验证阶段，不能由不信任的开发人员选择和修改。\n应用/事务执行过程\n 客户端将事务发送给背书策略指定的背书节点，这些节点执行事务并记录执行结果、输出，这一步又叫做背书(endorsement) 背书节点执行后，事务进入排序环节: 使用可替换的共识协议对事务进行排序，分类、聚合成区块；fabric 对事务在执行阶段的输出和依赖状态进行排序。在验证阶段每个节点只需验证状态改变和一致性 通过 gossip 协议将排序后的结果广播到所有节点  角色划分 为了实现执行 -排序-确认架构，fabric 网络中存在三种角色：\n 客户端(client): 提交事务提案到执行节点，协调执行阶段，将结果广播到排序节点 节点: 执行事务，验证正确性。所有节点均维护区块链账本(只允许 append 操作的数据库)已经当前的最新状态。只有 chaincode 策略定义的背书节点(endorsing peer)需要执行提案 排序服务节点(orderers): 对所有被验证过的事务(每个事务都包含状态更新和在执行阶段计算的依赖关系)进行排序，排序节点无需感知具体应用细节(chaincode)，也不参与事务的执行与验证。  事务执行过程与节点交互关系如图所示，有关交易流程的源码分析可以参考笔者的另一篇文章:\nfabric 同样支持：\n 一个物理节点扮演多种角色: 类似传统区块链网络一样，单个节点负责执行，验证，排序。 多链网络: fabric 可以存在用 channels 划分的多个区块链网络, 每个网络中交易/事务互相独立。多个区块链网络也可以共用一个排序服务 fabric 账本中不止包括合法的交易，也包含失败/非法的交易用于追踪。例如节点 接受区块时会对读写集状态进行检测，若与当前版本不匹配 ，将该事务设为失败。  模块介绍 为实现这种架构，fabric 包含了以下几个模块化部件\n 排序服务(Ordering service): 将状态改变原子广播到所有节点；通过共识对事务进行排序 身份与关系管理(Identity and membership): 将节点与加密身份关联，维护权限和身份管理, 可存在多个MSP 可扩展的广播服务(Scalable dissemination): 可配置的点对点广播服务，用于向所有节点广播排序服务产生的区块信息：  1.分为两个方式(push-pull)，推送阶段随机选取部分广播子集广播，拉取阶段定期选取一组节点请求丢失的消息。 2.为了减轻排序节点广播区块到全网的压力，fabric 会选取leader节点，可以从排序节点订阅新区块产生消息并进行分发 3.当节点新加入或长时间断开连接，这一模块也负责同步   智能合约组件(Smart-contract execution): Fabric的基本行为是通过渠道配置和特殊的链码（称为系统链码）定制的。链码以容器的形式执行，不能直接访问账本状态 账本管理(Ledger maintenance): 每个节点维护的只允许追加的账本，以键值对的形式表示当前区块链状态的快照(LevelDB或Apache CouchDB)，维护索引，用于随机访问块或块中的事务 "
            }
        
    ,
        
            {
                "ref": "https://yinminghao.top/post/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95%E5%88%99.html",
                "title": "程序员工作法则",
                "section": "post",
                "date" : "2020.08.03",
                "body": " 本文为郑晔老师的10x程序员工作法学习笔记\n 第 0 讲 大部分程序员忙碌解决的问题，都不是程序问题，而是由偶然复杂度导致的问题。\n四项原则  以终为始 任务分解 沟通反馈 自动化  第 1 讲 优秀程序员的开发效率是普通程序员的 10 倍\n思考框架  现状（where are we？)  我现在是什么水平？   目标（where are we going？）  我想达到什么目标？   实现路径（how can we get there？）  怎么达到目标？    思考原则  为什么要做这个特性，它会给用户带来怎样的价值？ 什么样的用户会用到这个特性，他们在什么场景下使用，他们又会怎样使用它？ 达成这个目的是否有其它手段？是不是一定要开发一个系统？ 这个特性上线之后，怎么衡量它的有效性？  我们不是一个人孤独地在工作，而是与其他人在协作，想要做到高效工作，我们就要“抬起头”来，跳出写代码这件事本身。程序员解决的问题，大多不是程序问题。\n第 2 讲 如果让你设计一个登录功能，你会怎么做？ os: 前端展示 + 服务端（api，token）+ db\n以终为始：反直觉的思维方式 事物创造：头脑中创造、付诸实践\neg：产品\n 给用户看产品的样子：原型工具而不是完整开发后 呈现服务接口：模拟服务器搭建服务 定义开发细节：给出各种场景下软件的行为  规划和发现 eg：物联网开发平台\n 考虑用户会怎么使用我们的平台  用户到我们的官网，按照文档一步一步做 根据使用文档讨论，得出最终的产品形态   锁定目标，开始写代码  践行“以终为始”就是在做事之前，先考虑结果，根据结果来确定要做的事情\neg：亚马逊产品开发顺序\n 写新闻稿 写FAQ 写用户文档 写代码  第 3 讲 DoD:Definition of Done\n eg：\n 特性开发完成，表示开发人员经过了需求澄清、功能设计、编写代码、单元测试，通过了测试人员的验收，确保代码处于一个可部署的状，相关文档已经编写完毕。 开发完成，表示开发人员编写好功能代码，编写好单元测试代码，编写好集成测试代码，测试可以通过，代码通过了代码风格检查、测试覆盖率检查。   个人层面  DoD是一个清单，清单是由一个个检查项组成，用于检查工作的完成情况 DoD的检查项应该是实际可检查的 DoD是团队成员彼此汇报的一种机制  DoD做事只有两种状态，做完与没做完    团队层面  功能DoD：功能特性已经开发完成，经过产品负责人的验收，处于一个可部署的状态 一个迭代的 DoD，比如：这个迭代规划的所有功能已经完成。 一次发布的 DoD，比如：整个软件处于可发布的状态，上线计划已明确  DoD是一个思维方式，是一种尽可能消除不确定性，达成共识的方式：在做任何事之前，先定义完成的标准。\n第 4 讲 需求描述的问题 User Story\n 标题，简要说明用户故事的主要内容：注册用户使用用户名密码登陆。 概述，介绍用户故事的主要内容，一般格式：As a (Role),I want to (Acitity), so that (Business Value).：作为一个注册用户，我想要通过账户密码登陆，以便使用注册用户才能使用的服务。 详述，详细的描述这个用户故事的完整流程，把操作流程，用户界面信息放在这里。    比如：用户使用正确用户名和密码登录，就可以登录成功；如果密码不正确，则登录页面提示用户“用户名密码不正确”。基本上，看到这个部分，程序员就可以在心中描绘出这个用户故事的样子了。\n超出范围的部分，比如：第三方登录不在范围内，这个部分主要是限定人们不要进一步发散。\n   验收标准，这个部分会描述一个正常使用的流程是怎样的，以及各种.异常流程系统是如何给出响应的，这是程序员常常会欠缺的思考。它会把详述中很多叙述的部分变成一个具体的测试用例。比如：    正常场景：给定一个注册用户张三，其用户名是 zhangsan，密码是 foobar，当张三使用 zhangsan 和 foobar 登录系统时，可以成功登录，登录成功后，跳转到用户中心。\n异常场景：给定一个注册用户张三，其用户名是 zhangsan，密码是 foobar，当张三使用 zhangsan和 wrong 登录系统时，登录失败，在登录页面上提示“用户名密码不正确”。\n  验收标准非常重要的一环是异常流程的描述 验收标准给出了这个需求最基本的测试用例，它保证了开发人员完成需求最基本的质量：BDD(Behavior-Driven Development/行为驱动开发)\n最好维护的代码是没有写出来的代码\n第 5 讲 集成 尽早提交代码去集成\n第 6 讲 默认所有需求都不做，直到弄清楚为什么要做这件事。\n 不管什么需求先做出来看看。殊不知，把完整的需求做出来才是最大的浪费。最后真是看看而已\n 第 7 讲 不同角色工作上真正的差异是上下文的不同。\n 技术是一把利刃，程序员相信技术可以改变世界，但并不是所有问题都要用技术解决。有这样一种说法，手里有了锤子，眼里都是钉子。花大力气去解决一个可能并不是问题的问题，常常是很多程序员的盲区。\n 扩大自己工作的上下文，别把自己局限在一个“程序员”的角色上。\n第 8 讲 最后一公里：完成一件事，在最后也是最关键的步骤\n 先从结果的角度入手，看看最终上线需要考虑哪些因素 推演出一个可以一步一步执行的上线方案，用前面考虑到的因素作为衡量指标 根据推演出来的上线方案，总结要做的任务  结果是重要的，通向结果的路径是更重要的\n 对比我们的工作，多数情况下，即便目标清晰，路径却是模糊的。所以，不同的人有不同的处理方式。有些人是走到哪算哪，然后再看，有些人则是先推演一下路径，看看能走到什么程度。\n 例子\n 在做一个产品之前，首先推演一下这个产品如何推广，通过什么途径推广给什么样的人 在做技术改进之前，先考虑上线是一个怎样的过程，为可能出现的问题准备预案 在设计一个产品特性之前，先考虑数据有谁提供，完整的流程是什么样的  动手做一件事之前，先推演一番\n第 9 讲 精益创业-反馈循环：开发(build) - 测量(measure) - 认知(learn)\n 最好的检验标准是数字\n 从数字上看，好的系统应该是“死水一潭”\n第 10 讲 迭代 0 清单  需求方面\n 细化过的迭代 1 需求\n 需求分解\n细化需求\n优先级 用户界面和用户交互\n    技术方面  基本技术准备  技术选型、技术架构、数据库表结构 持续集成  构建脚本 构建IDE工程、代码风格检查、bug模式检查、测试覆盖率 测试(把测试覆盖率加入构建脚本)     发布准备  数据库迁移  flyway(管理数据库工具)   发布  Docker(Dockerfile) Shell        日常工作 第 11 讲 管理领导  管理上级的预期  时间压缩会影响什么，做这个调整放弃的东西是什么   帮助上级丰富知识 说出自己的想法  第 12 讲 软件开发的任务分解 不同的可执行定义差别在于，你是否能清楚的知道这个问题该如何解决\n如今软件行业都在提倡拥抱变化，而任务分解是我们拥抱变化的前提\n动手做一个工作前，先对它进行任务分解\n第 13 讲 软件变更成本，它会随着时和开发阶段逐步增加\n 内建质量\n 对于每个程序员来说，只有在开发阶段把代码和测试都写好,才有资格说，自己交付的是高质量的代码。\n  自动化测试(XUnit测试框架) 这种测试框架最大的价值，是把自动化测试作为一种最佳实践引入到开发过程中，使得测试动作可以通过标准化的手段固定下来。\n测试模型：蛋卷与金字塔 越是底层的测试，牵扯到相关内容越少，而高层测试则涉及面更广。 小事反馈周期短，而大事反馈周期长\n所以，虽然冰淇淋蛋卷更符合直觉，但测试金字塔才是行业的最佳实践 第 13 讲 TDD（测试驱动开发） 测试先行开发和测试驱动开发的差异就在重构上。 因为重构和测试的互相配合，它会驱动着你把代码写得越来越好\n测试驱动设计 我的代码怎么写才是能测试的，也就是说，我们要编写具有可测试性的代码\n第 14 讲 每个任务完成之后，代码都是可以提交的。\n微操作 任务分解的关键在于小\n我们写程序的时候，都不喜欢被打扰，因为一旦被打扰，接续上状态需要很长一段时间，毕竟，我们可不像操作系统那么容易进行上下文切换。\n但如果任务足够小，完成一个任务，我们选择可以进入到下一个任务，也可以停下来。这样，即便被打扰，我们也可以很快收尾一个任务，不致于被影响太多。\n一个经过分解后的任务，需要关注的内容是有限的，我们就可以针对这个任务，把方方面面的细节想得更加清晰\nFeature toggle（功能开关） https://martinfowler.com/articles/feature-toggles.html\nhttps://www.infoq.cn/article/function-switch-realize-better-continuous-implementations\n第 15 讲 需求：用户通过输入用户名和密码登陆\n 用户注册用户名 注册用户通过输入用户名和密码登陆 登陆用户退出  任务分解\n 数据库内容  设计用户信息表 编写用户信息表的数据库迁移  数据库迁移工具选型     编写代码  REST服务对外提供访问  领域对象(用户) 数据库访问层 服务层 资源层      很多人可能更习惯一个类一个类的写，我要说，最好按照一个需求、一个需求的谢，这样任务是可以停下来的\n按照完整实现一个需求的顺序去安排分解出来的任务。\n第 16 讲 主要是因为这些测试不够简单。只有将复杂的测试拆分成简单的测试，测试才有可能做好\n 前置准备  准备执行部分所需要的依赖(mock框架)   执行  往往是一行待测试代码的调用   断言  预期，判断代码执行的验收标准   清理  一段旅程(A-TRIP)  Automatic 自动化 Thorough 全面的  测试应该尽可能覆盖各种场景   Repeatable 可重复的 Independent 独立的 Professional 专业的  第 17 讲 基本上，闯入你脑海的需求描述是主题（epic），在敏捷开发中，有人称之为主用户故事(master story)\n想要管理好需求，先把需求拆小\n第 18 讲 尽量做重要的事情\n第 19 讲 我们要做的是验证一个想法的可行性，甚至不是为了开发一个软件，开发软件只是一种验证手段\n从产品可行的角度，我们需要转换一下思路，不是一个模块做得有多完整，而是一条用户路径是否畅通\n答疑：分解任务 如果不了解这项技术呢？答案很简单，先把它变成你熟悉的技术\n 技术spike\nSpike 的作用就在于消除不确定性，让项目经理知道这里要用到一个全团队没有人懂的技术，需要花时间弄清楚  这项技术在项目中应用场景和我们的关注点。  直奔结果，防止发散 开发原型，验证假设   丢掉原型代码    项目时间紧，该怎么办\n 混淆了目标和现状   改进过程\n 把测试覆盖率检查加入到工程里，得到现有的测试覆盖率。\n将测试覆盖率加入持续集成，设定当前测试覆盖率为初始值。测试覆盖率不达标不允许提交代码。 每周将测试覆盖率提高，直到100%\n  多个功能同时开发，怎么办\nFeature Toggle 是最常用的一个，也就是通过开关，决定哪个功能是对外可用的\n Feature Toggle 使用功能开关更好地实现持续部署  第 20 讲 我们努力地学习各种知识，为的就是更好地理解这个世界的运作方式,而沟通反馈，就是我们与真实世界互动的最好方式。\n改善编解码 程序员讲东西的通病：讲东西直奔细节。\n第 21 讲 编写可维护的代码《程序设计实践》\n 任何人都能写出计算机能够理解的代码，只有好程序员才能写出人能理解的代码\n 用业务的语言写代码。\n第 22 讲 (你总是在开会吗) 改善会议  改善会议的第一个行动项是，减少参与讨论的人数 我们的第二个行动项是，如果你要讨论，找人面对面沟通  开会的目的不是讨论，而是同步   站立会议  做了什么 要做什么 问题求助     Amazon 的开会方式值得借鉴。https://www.36kr.com/p/203274\n 5-12人是一个恰当的团队规模\n第 23 讲 (可视化:一种更直观的沟通方式) 技术网站  InfoQ ThoughtWorks技术雷达  Event Storming 事件风暴    构建技术雷达  构建技术雷达 构建雷达的程序库  处理图像的速度远远快于处理文字\n限制 WIP：一个人多线程工作，效果不会好\n第 24 讲 (快速反馈:为什么你的公司总是做不好持续集成) 快速反馈 执行同样的操作，本地环境会快于ci服务器环境\n有效反馈 CI 服务器一旦检查出错，要立即修复\n怎么引人注目，怎么呈现\n第 25 讲 (开发中的问题一再出现，怎么办) 复盘(客体化) 这种把过程还原，进行研讨与分析的方式，就是复盘。\n回顾会议\n 做得好的 做得差的 问题建议  写事实，不要写感受\n所有给出的行动项应该都是可检查的，而不是一些无法验证的内容\n责任人\n五个为什么 eg： 为什么服务器返回504\n 处理时间长？超时了 为什么超时？Redis卡住了 为什么卡住？一个更新服务删除大量数据，重新插入阻塞了 为什么有大批量删除数据重新插入？更新算法设计的不合理 为什么一个设计得不合理的算法就能上线呢？因为这个设计没有按照流程进行评审  定期复盘，找准问题根因，不断改善\n 首先，对比实际结果与预期的差异 情景再现，回顾项目的几个阶段 对每个阶段进行得失分析，找出问题原因 总结规律，技能沉淀，再次遇到时可以规避（文档形式记录下来）  第 26 讲 | 作为程序员，你也应该聆听用户声音 TO C：多走进用户\n在挑毛病找问题这件事上，人是不需要训练的，哪里用着不舒服，你一下子就能感受的到\n第 27 讲 | 尽早暴露问题： 为什么被指责的总是你？ 并不是所有的问题，都是值得解决的技术难题\n遇到问题，最好的解决方案是尽早把问题暴露出来\nFail Fast 事情往前做，有问题尽早暴露\n及时反馈及时沟通（计划SIT、UAT、灰度发布等时间节点倒推的形式进行）\n第 28 讲 | 结构化：写文档也是一种学习方式 将零散的知识结构化，有很多种方式，但输出是非常关键的一环。\n知识输出 输出的过程，本质就是把知识连接起来的工程\n金字塔原理 多输出，让知识更有结构\n第 29 讲 | “懒惰”应该是所有程序员的骄傲 做有价值的事是重要的，这里面的有价值，不仅仅是“做”了什么，通过“不做”节省时间和成本也是有价值的。\n小心 NIH 综合症 写代码之前，先问问自己真的要做吗？能不做就不做，直到你有了足够的理由去做\n做好自动化 懂得软件设计 以现在大家的努力程度，少做点事是需要锻炼的技能。\n第 30 讲 | 一个好的项目自动化应该是什么样子的？ 数据库迁移工具：Flyway\n必须明确的一点，这两个业务模块之间是服务相互调用的关系，不是程序库的关系。\n第 31 讲 | 程序员怎么学习运维知识？ 开发知识体系\n运维知识体系\n现在运维流行DevOps，高级一点就是AI：\n DevOps 详解 DevOps知识体系与标准化的构建 运维知识体系 Web缓存知识体系  运维技能：\n 懂网络：  一般要求CCNA（最好CCNP）或同等水平   懂系统：  懂得主流的linux系统操作（Centos、ubuntu、debian等） 操作命令、维护、性能优化、故障排查   简单安全：  一些简单的安全知识   半个DBA：  一般中小公司前期没有DBA，需要运维做 最起码会SQL语句、主从群集：redis、mysql、MongoDB等   会运维开发：  一般用于开发运维工具、运维系统（如CMDB、ELK日志系统等） 运维主要语言是shell、python/Go python web框架：Django、tonado等 Go web框架：Beego、Gin、Iris等 有的还会用PHP及框架（TP、YII、Laravel做web前端） 中小公司运维一般都没有专职的前端，需要运维兼职所以要学前端知识   懂点开发：  一般都懂一点本公司开发的语言，如公司用PHP需要学习、如公司用java web也需要学习一下，目标：  更好的维护网站，排错 运维自动化、DevOps，因DevOps是基于敏捷开发，极限编程的思想，所以得懂一点软件工程     主职：  各种环境的搭建：LAMP、LNMP、负载均衡(nginx、haproxy、VLS等)、web群集、数据库群集、主流的docker[必会] 排错[必会] 批量安装系统安装：Cobbler[少] 部署工具：Ansible/SaltStack[重要] 主流的部署方案：如云、docker、k8s等[必会] 监控系统：zabbix、Open-Falcon[至少掌握其中一种] 自动化：gitlab CI/CD、jenkins结合ansible/salt、docker[必会] 运维流程的制定 减少背锅的次数：运维是出名的“背锅侠”，制定明确的责任可以减少背锅 等等   会点构架  一般中小公司没有构架师，所以当业务增大出现瓶颈，运维得给出解决方案 和开发讨论如何扩展    第 32 讲 | 持续交付：有持续集成就够了吗？ 持续交付 一般来说，在构建持续交付的基础设施时，会有下面几个不同的环境:\n 持续集成环境，持续集成是持续交付的前提，这个过程主要是执行基本的检查，打出一个可以发布的包 测试环境（Test），这个环境往往是单机的，主要负责功能验证。这里运行的测试基本上都是验收测试级别的，而一般把单元测试和集成测试等执行比较快的测试放到持续集成环境里。 预生产环境（Staging），这个环境通常与生产环境配置是相同的。比如，负载均衡，集群之类的都要有，只是机器数量上会少一些，主要负责验证部署环境，比如，可以用来发现由多机并发带来的一些问题 生产环境（Production），这就是真实的线上环境了。   DevOps Docker\n将部署纳入开发的考量\n第 33 讲 | 如何做好验收测试？ 验收测试 行为驱动开发（Behavior Driven Develop）\n 如果你想做BDD， 就应该用业务语言进行描述  目前流行的BDD框架 Cucumber    写好验收用例 想写好BDD的测试用例，关键点在于以业务视角描述\n web测试模型 Page Object\n 将验收测试自动化。\n第 34 讲 | 你的代码是怎么变混乱的？ SOLID原则 高内聚，低耦合\n 单一职责原（Single responsibility principle，SRP） 开放封闭原则（Open-closed principle， OCP） Liskov替换原则（Liskov substitution principle，LSP） 接口隔离原则（Interface segreation principle，ISP） 依赖倒置原则（Dependency inversion principle，DIP）  Robert Martin 《敏捷软件开发：原则、实践与模式》\n第 35 讲 | 总是在说MVC分层架构，但你真的理解分层吗？  数据访问层，按照传统的说法，叫 DAO（Data Access Object，数据访问对象），按照领域驱动开发的术语，称之为 Repository； 服务层，提供应用服务； 资源层，提供对外访问的资源，采用传统做法就是 Controller  人们擅长解决的是小问题，大问题怎么办？拆小了就好。\n分层架构，实际上是在设计上的分解\n分层的价值：构建一个良好的抽象\n服务层/领域模型（Domain Model） 你的领域层只依赖于你的领域对象，第三方发过来的内容先做一次转换，转换为你的领域对象\n第 36 讲 | 为什么总有人觉得5万块钱可以做一个淘宝？ 淘宝的发展历程 淘宝技术这十年\n LAMP 定制化工作（数据库拆分：一主二从）  数据库瓶颈（MySQL换成Oracle/开源连接池SQL Relay）  数据量增大，本地存储无法满足，购买小型机（IOE：IBM的小型机，Oracle数据库，EMC的存储） 语言痛点（SQLRelay）跟换程序设计语言（PHP - JAVA）  业务分模块，老模块只维护，新老模块公用数据库，新功能上线，关闭老模块对应功能，所有模块替换完毕，老模块下线   单台Oracle达到上线：分库分表模式  跨数据库数据怎么整合：DBRoute   同时链接多个数据库，任何一个数据库出现问题，都会导致整个网站故障，此外随着数据量继续增加。每次访问数据库，数据库很难承受（引入缓存、CDN（内容分发网络）） 商用CDN随着流量增加支撑不住，搭建自己的CDN CDN消耗大量的服务器资源，研发自己的低功耗服务器 业务发展，开发人员增多，系统臃肿，耦合度提升，对系统分解，拆分复用性高的模块：用户信息 业务继续发展，底层业务与上层剥离，所有业务模块化 打造自己的解决方案：分布式文件系统（TFS）、缓存系统（Tair），分布式服务框架（HSF）  同样的业务，不同的系统 关键点在于不同的业务量\n淘宝的工程师之所以要改进系统，真实的驱动力不是技术，而是不断攀升的业务量带来的问题复杂度。\n用简单技术解决问题，直到问题变复杂。\n第 37 讲 | 先做好DDD再谈微服务吧，那只是一种部署形式 微服务 怎么划分微服务，一个庞大的系统按照什么样的方式分解\n 领域驱动设计（DDD）  战略设计（Strategic Design） 战术设计（Tactical Design）   走向微服务  界定上下文 划分模块 演化到值得独立部署 微服务拆分    第 38 讲 | 新入职一家公司，怎么快速进入工作状态？  运用思考框架  where are we where are we going how can we get there（做什么而不是怎么做）   分解目标  业务  了解业务模型，解决什么问题，业务流程是什么 思考整体框架：我来做会是什么样的 模糊细节   技术  技术栈 业务架构  模块 与那些外部系统交互   对外接口？集成那些外部系统（RPC/MQ） 协议（json、protocol、thrift） 分层结构 动手构建脚本等   团队运作  对外有那些接口  需求来源 用户 团队向谁汇报 外部用户日常沟通   对内  定期活动（周会、站会） 代码评审等 内部分享        第 39 讲 | 面对遗留系统，你应该这样做 分清现象与根因 确定方案 先尝试重构你的代码，尽可能在已有代码上做小步调整，不要走到大规模改造的路上，因为重构的成本是最低的。\n修改代码的艺术\n 足够的测试，若不足。先补测试用例 替换遗留系统：分成小块，逐步替换 新代码按照行业内最佳实践来做，减少代码的腐化速度  不要回到老路上\n第 40 讲 | 我们应该如何保持竞争力？ 成为 T 型人 一专多能\n有了“一专”，“多能”才是有意义的，否则，就是低水平重复，而这正是很多人职业生涯不见起色的真正原因。\n这里的“专”不是熟练，而是深入\n一专 拥有了深厚的技术功底\n 带着他人一起做好，成为技术领导者 分享技术的理解，成为培训师 实战中帮别人解决问题，成为咨询师  多能  拓宽视野，帮助自己一专怎么更好的发挥价值   如果让你再一次技术大会上做分享，你会讲什么\n 在学习区成长 向行业中的大师学习\n找一个好问题去解决\n 如果你还什么都不会，那有一份编程的工作就好。 如果你已经能够写好普通的代码，就应该尝试去编写程序库 如果实现一个具体功能都没问题了，那就去做设计，让程序有更好的组织 如果你已经能完成一个普通的系统设计，那就应该去设计业务量更大的系统  如果你真的能够不断向前进步，迟早会遇到前面已经没有铺就好的道路，这时候，就轮到你创造一个工具给别人去使用了。\n书单"
            }
        
    ,
        
            {
                "ref": "https://yinminghao.top/post/fabric%E4%BA%A4%E6%98%93%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html",
                "title": "Fabric交易源码分析",
                "section": "post",
                "date" : "2020.08.03",
                "body": "本系列为对 fabric release-2.1 版本代码阅读的记录，如有不当之处，烦请指正\n 本文对在一个正常运行fabric网络下交易的追踪，了解 fabric 的内部处理方式，文章主要针对交易流程中关键的步骤进行说明，具体的实现方式和代码细节不在本文讨论范围，感兴趣的读者可以自行阅读相关代码。为了避免出现冗长的代码段，一些判断、错误处理的代码将被省略。\n 背景知识 本文假定读者对 fabric 机制有一定了解，如果和笔者一样是之前没有接触过 fabric, 可以从官方文档入手，也可以查看笔者的另一篇对 fabric 介绍的文章。\n对交易流程的介绍可以查阅文档Transaction Flow。在运行之前，我们假定： 1. 网络中存在正常运行的 chan (利用通道可以同时参与多个、彼此独立的区块链网络)。 2. 网络中的节点、用户均使用组织CA完成注册、登记并获得确认身份的加密证明。 3. chaincode(链码,定义交易的执行逻辑：定价规则，背书策略等)已经在 Peer 节点上安装并在通道上完成了实例化。\n除正常的交易之外，本文也包含私有数据的处理逻辑，关于私有数据介绍可查阅附录, 当在链码中引用私有数据集合时，为了保护私有数据在提案、背书和提交交易过程中的机密性，私有数据的交易流程略有不同。 交易流程 我们从源码中的 chaincodeInvoke 函数(internal/peer/chaincode/invoke.go#L46) 这一客户端调用开始，分析 fabric 网络中三种角色(客户端、背书节点、排序节点)在交易(提案)生命周期中的行为与处理逻辑。\n一、 客户端 客户端构造交易提案并将其发送到 Endorser (背书)节点，交易提案中包含本次交易要调用的合约标识、合约方法和参数信息以及客户端签名等。获取到 Endorser (背书)节点背书后组装成新的消息 Envelope 发送到 order (排序)节点\n当客户端提案调用一个链码函数来读取或写入私有数据时，会将私有数据(或用于在链码中生成私有数据的数据)放在提案的 transient 字段中发送给被授权的背书节点。\nfunc chaincodeInvoke(...) { // 构造 ChaincodeCmdFactory, 包含背书节点 client API,  // 签名器、客户端的 TLS 证书，代理节点等  cf, err = InitCmdFactory(cmd.Name(), true, true, cryptoProvider) // chaincodeInvokeOrQuery 调用 chaincode 并获取返回值  return chaincodeInvokeOrQuery(cmd, true, cf) } func ChaincodeInvokeOrQuery(...) (*pb.ProposalResponse, error) { // 构建提案(Proposal:可以描述交易), 输入参数包括调用的合约标识、合约方法和参数信息等  // tMap: 私有数据，或用于在链码中生成私有数据的数据。  prop, txid, err := protoutil.CreateChaincodeProposalWithTxIDAndTransient(..., tMap) // 签名提案/交易  signedProp, err := protoutil.GetSignedProposal(prop, signer) // 发送签名后的提案到背书节点并获取返回各个背书节点对该提案的响应  responses, err := processProposals(endorserClients, signedProp) // 获取背书后组装成 Envelope message, 包括合法性校验  env, err := protoutil.CreateSignedTx(prop, signer, responses...) // 发送 Envelope message 到排序节点  bc.Send(env) } 关键数据结构\n// 发送到背书节点的 Proposal type Proposal struct { Header: ChannelHeader: // 包括txid、时间戳, chanId等信息  SignatureHeader: // 签名  Payload: // 执行 chaincode 的输入 } // 发送到排序节点的 Envelope message type Envelope struct { SignatureHeader: // 签名  Header: Proposal.Header Data: []*TransactionAction } type Transaction struct { Header: Proposal.Header Payload: ChaincodeProposalPayload: // 执行 chaincode 的输入: 请求智能合约的函数名、参数等  Action: ProposalResponsePayload: // 链码模拟执行结果,对KV类型状态数据库的读写集  Endorsements: // 提案的背书，基本上是背书节点在payload的签名 } 二、 背书节点 背书节点收到客户端交易提案后，会模拟执行交易，然后将原始交易提案和执行结果打包到一起，进行签名并发回给客户端，其中在模拟执行交易期间产生的数据修改不会写到账本上。\n背书节点处理私有数据时，会将其存储在 transient data store （节点的本地临时存储库）中。然后根据组织集合的策略将私有数据通过 gossip 分发给授权的节点。背书节点将提案响应(背书的读写集)发送给客户端，包含了公共数据，还包含任何私有数据键和值的哈希。私有数据不会被发送回客户端。\n// ProcessProposal process the Proposal func (e *Endorser) ProcessProposal(signedProp *pb.SignedProposal) (*pb.ProposalResponse) { // 返回没有零字段的 UnpackedProposal  up := UnpackProposal(signedProp) // 第一步: 检查 proposal headers 合法性等  // checks the tx proposal headers, uniqueness and ACL  e.preProcess(up, channel) // 预执行 Proposal  pResp := e.ProcessProposalSuccessfullyOrError(up) return pResp } func (e *Endorser) ProcessProposalSuccessfullyOrError(up *UnpackedProposal) (*pb.ProposalResponse) { // 第二部: 根据 chaincode 模拟 proposal 执行结果,  res, simulationResult, ccevent := e.SimulateProposal(txParams, up.ChaincodeName, up.Input) // 封装事物执行的结果  simResult, err := txParams.TXSimulator.GetTxSimulationResults() } func (e *Endorser) SimulateProposal(...) (*pb.Response, []byte, *pb.ChaincodeEvent, error) { ... // ---执行提案并获取结果 调用链最后调用 handleTransaction函数  // =\u0026gt; e.Support.Execute(txParams, chaincodeName, input) =\u0026gt; handleTransaction(...)  res, ccevent, err := e.callChaincode(txParams, chaincodeInput, chaincodeName) // 封装事物执行的结果  simResult, err := txParams.TXSimulator.GetTxSimulationResults() // 添加与私有读写集相关的可用集合配置信息  pvtDataWithConfig, err := AssemblePvtRWSet(txParams.ChannelID, simResult.PvtSimulationResults, txParams.TXSimulator, e.Support.GetDeployedCCInfoProvider()) // 根据组织集合的策略将私有数据通过 gossip 分发给授权的节点。  e.PrivateDataDistributor.DistributePrivateData(txParams.ChannelID, txParams.TxID, pvtDataWithConfig, endorsedAt) // 返回公共读写集， 不返回私有数据  pubSimResBytes, err := simResult.GetPubSimulationBytes() return res, pubSimResBytes, ccevent, nil } // 调用 chaincode // vendor/github.com/hyperledger/fabric-chaincode-go/shim/handler.go#L195 func (h *Handler) handleTransaction(msg *pb.ChaincodeMessage) (*pb.ChaincodeMessage, error) { // Invoke is called to update or query the ledger in a proposal transaction.  // Updated state variables are not committed to the ledger until the  // transaction is committed.  // 根据 proposal 更新、查询账本，但在交易 transaction 被提交前数据更改不会体现在账本上  // 返回执行结果, 具体的执行逻辑由 chaincode 定义。  res := h.cc.Invoke(stub) } 对私有消息的处理(DistributePrivateData): 节点分发私有数据到被授权节点，这些节点暂存收到的私有数据\n// 初始化 gossip 节点时为消息接受配置规则 func NewGossipStateProvider(...) { ... // commChan 远程peer的请求或响应信息  // 实现方式 : 在 ChannelDeMultiplexer 注册消息订阅, 满足过滤规则 remoteStateMsgFilter 消息会塞到 commChan 中  // remoteStateMsgFilter 包括权限、chan等检测  _, commChan := services.Accept(remoteStateMsgFilter, true) ... // 消息监听处理  go s.receiveAndDispatchDirectMessages(commChan) } // 处理收到的数据 func (s *GossipStateProviderImpl) receiveAndDispatchDirectMessages(ch \u0026lt;-chan protoext.ReceivedMessage) { for msg := range ch { go func(msg protoext.ReceivedMessage) { ... if gm.GetPrivateData() != nil { // 处理收到的私有数据(暂存), 调用链最后到 Persist()  // =\u0026gt; Persist()  s.privateDataMessage(msg) } }(msg) } } // 其他授权节点收到私有数据将其暂存在 transient store // https://github.com/hyperledger/fabric/blob/07c468def167e83ea85d46d795113a98cb6081a1/core/transientstore/store.go#L103s // 根据 txid 和 block 高度存储 func (s *Store) Persist(...) error {} 三、 排序节点 Orderer(排序节点)对接收到的 Envelope message 进行排序，然后按照区块生成策略，将一批交易打包到一起，生成新的区块。在网络中共识(solo,raft,kafka，本文以raft为例)，完成所有节点账本的更新。带有私有数据哈希的区块被分发给所有节点。这样节点可以在不知道真实私有数据的情况下，来验证带有私有数据哈希值的交易。\n// ProcessMessage validates and enqueues a single message func (bh *Handler) ProcessMessage(msg *cb.Envelope, addr string) (resp *ab.BroadcastResponse) { // 合法性验证  ... // 调用 chan 的共识进行排序(solo, raft, kafka)  processor.Order(msg, configSeq) } 共识算法：Raft 介绍, 有时间可以再写一下 etcd raft 的实现\n// func (c *Chain) Submit(req *orderer.SubmitRequest, sender uint64) error { select { case c.submitC \u0026lt;- \u0026amp;submit{req, leadC}: lead := \u0026lt;-leadC // 没有leader，返回错误  if lead == raft.None { return errors.Errorf(\u0026#34;no Raft leader\u0026#34;) } if lead != c.raftID { // 该节点不是 leader, 发送请求到 leader 节点  if err := c.rpc.SendSubmit(lead, req); err != nil { return err } } } } func (c *Chain) run() { ... select { // leader 对 Envelope message 的处理  case s := \u0026lt;-submitC: // batches 请求裁剪成[]Env、pending 判断是否有待排序的Env  batches, pending, err := c.ordered(s.req) // =\u0026gt; createNextBlock  block := c.propose(propC, bc, batches...) // leader 提议添加新的日志  // raft 共识，收集足够的票完成 commit  c.Node.Propose(ctx, block) // 达成共识后，更新账本  case app := \u0026lt;-c.applyC: // =\u0026gt; c.support.WriteBlock(block, m) 提交 block 到账本  c.apply(app.entries) } ... } 节点存储区块 在区块提交的时候，节点会根据集合策略来决定它们是否有权访问私有数据。如果有访问权，则先检查本地 transient data store ，以确定它们是否在链码背书的时候已经接收到了私有数据。如果没有收到私有数据，就会尝试向其他已授权节点请求私有数据，然后对照公共区块上的哈希值来验证私有数据并提交交易和区块。 当验证或提交结束后，私有数据会被移动到这些节点私有数据库和私有读写存储的副本中。随后 transient data store 中存储的这些私有数据会被删除。\n// 处理 order 节点发来的消息 func (s *GossipStateProviderImpl) deliverPayloads() { // 提交区块  // =\u0026gt; StoreBlock()  s.commitBlock(rawBlock, p) } // 存储 block 和 私有数据 func (c *coordinator) StoreBlock(block *common.Block, privateDataSets util.PvtDataCollections) error { // ... 合法性检测 \tblockAndPvtData := \u0026amp;ledger.BlockAndPvtData{ Block: block, PvtData: make(ledger.TxPvtDataMap), MissingPvtData: make(ledger.TxMissingPvtDataMap), } // 查询是否能从本地账本获取到私有数据  exist := c.DoesPvtDataInfoExistInLedger(block.Header.Number) if exist { // 从账本获取私有数据  commitOpts := \u0026amp;ledger.CommitOptions{FetchPvtDataFromLedger: true} // 私有数据已存在，提交 block 和私有数据  return c.CommitLegacy(blockAndPvtData, commitOpts) } ... // 解析区块，获取私有数据列表  pvtdataToRetrieve, err := c.getTxPvtdataInfoFromBlock(block) // 获取私有数据  // 这一步会检查节点的资格，然后从缓存，临时存储 TRANSIENT STORE 或其他节点检索  retrievedPvtdata, err := pdp.RetrievePvtdata(pvtdataToRetrieve) blockAndPvtData.PvtData = retrievedPvtdata.blockPvtdata.PvtData blockAndPvtData.MissingPvtData = retrievedPvtdata.blockPvtdata.MissingPvtData // 提交 block 和私有数据  c.CommitLegacy(blockAndPvtData, \u0026amp;ledger.CommitOptions{}) // 清除工作  retrievedPvtdata.Purge() } 附录 私有数据 在某个通道上的一组组织需要对该通道上的其他组织保持数据私密的情况下，它们可以选择创建一个新通道，其中只包含需要访问数据的组织。但是，在每一种情况下创建单独的通道会产生额外的管理开销（维护链码版本、策略、MSP 等），并且不允许在保持部分数据私有的同时，让所有通道参与者都看到交易。\n 在通道内什么时候使用私有数据集，什么时候使用单独通道\n 当通道成员的一群组织必须对所有交易（和账本）保密时，使用通道。 当交易（和账本）必须在一群组织间共享，并且这些组织中只有一部分组织可以访问交易中一些（或全部）私有数据时，使用集合。此外，由于私有数据是点对点传播的，而不是通过区块传播，所以当交易数据必须对排序服务节点保密时，应该使用私有数据集合。 返回正文  "
            }
        
    ,
        
            {
                "ref": "https://yinminghao.top/post/%E9%83%A8%E7%BD%B2hexo%E5%88%B0%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8.html",
                "title": "部署hexo到云服务器",
                "section": "post",
                "date" : "2020.08.03",
                "body": " 搜到的一般操作都是部署到github的静态页面上，个人因为先前买了一个阿里云服务器一直闲置，干脆就部署到阿里云上好了\n 以下部署过程以ubuntu18.04(1核1G)为例\n预装环境  安装 hexo (过程中出现问题可查阅附录) # 安装 node 与 npm $ sudo apt install nodejs # 安装 hexo $ npm install hexo-cli -g  安装 git $ sudo apt install git-all  安装 nginx $ sudo apt install nginx   推送到远程服务器  设置同步方式 : 编辑 blog/_config.yaml, 增加 rSync 同步方式 deploy: type: rsync host: **.**.**.** # 你的服务器ip user: root root: /usr/local/nginx/***.blog/ # 文件存放位置 port: 22  配置 git hook : blog/hooks/pre-push.sh, 在 每次git push后触发 #!/bin/sh # 推送到远程服务器 hexo g -d   配置nginx  配置 hexo.conf $ sudo vi /etc/nginx/conf.d/hexo.conf  配置全局 nginx.conf $ sudo vi /etc/nginx/nginx.conf  重启 nginx $ service nginx restart   附录 预装环境时出现的问题  node 版本过低 # 安装 node 版本管理工具 $ npm i -g n # 失败了可以试下 npm i -g n --force # 安装最近的稳定版本 $ n stable  npm 版本过低 $ npm i npm -g  ENOENT: no such file or directory, open \u0026lsquo;/Users/xxx/package.json\u0026rsquo; $ npm init   nginx 配置  hexo.confserver { listen 80; listen [::]:80; server_name yinminghao.top; # 自己的域名 root /usr/local/nginx/ymh.blog; access_log access.log; error_log error.log; location / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; } }  nginx.conf user root; worker_processes 1; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \u0026quot;$request\u0026quot; ' '$status $body_bytes_sent \u0026quot;$http_referer\u0026quot; ' '\u0026quot;$http_user_agent\u0026quot; \u0026quot;$http_x_forwarded_for\u0026quot;'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; gzip on; include /etc/nginx/conf.d/*.conf; }  "
            }
        
    ,
        
            {
                "ref": "https://yinminghao.top/post/fabric%E7%BD%91%E7%BB%9C%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html",
                "title": "Fabric网络源码分析",
                "section": "post",
                "date" : "2020.08.03",
                "body": "本系列为对 fabric release-2.1 版本代码阅读的记录，如有不当之处，烦请指正\n 本文对 fabric 的网络层代码进行分析，介绍其基本思想与代码实现，包括组网、身份验证与广播实现等，\n fabric 网络介绍 在之前的对 fabric 的介绍中，可以了解到 fabric 将交易(事务)执行、排序、验证进行分离，在这种设计下，我们可以对这些模块单独进行缩放。\n与其他两个阶段点对点传播消息不同，排序阶段会对收到的交易(事务)进行共识排序，并将其分发到网络中的各个阶段，因此对网络层有更高的要求。\n 大多数共识算法(例如CFT、BFT)都受带宽限制(笔者之前从事基于algorand共识的公链开发时也遇到了网络瓶颈, 在网络流量、延迟等方面做了大量工作)，fabric 的排序共识(raft)也同样共识受到其节点网络容量的限制。无法通过添加更多共识节点来提高吞吐量，相反节点的增多会影响共识的性能。\n fabric 采用 gossip 实现消息的广播。\ngossip 组件 区块通过 gossip 组件将排序服务签名后的区块广播到网络中其他节点，其他节点收到区块后验完整性组装成区块链。\nfabric 的通信层基于gRPC，并利用具有相互身份验证的TLS来保证消息的权限，gossip 组件维护系统中在线节点的成员认证关系并随时对其进行更新。\ngossip 作用与实现方式  gossip 采用 pull-push 协议在节点见之间可靠地分发消息。 为了减轻从排序节点向网络发送数据块的负担，fabric 会选择一个领导节点，该节点代表它们从排序服务中获取数据块并使用 gossip 进行分发。 在新节点加入或节点长时间断开连接时，gossip 负责这些节点的状态更新，也就是通常理解的同步作用  代码实现 fabric 的网络层基本在 gossip 包里实现\n- gossip - api - comm - common - discovery - election - filter - gossip - identity - metrics - privdata - protoext - service - state - util 组网 一个节点要加入网络，必须要知道一个已知的 Fabric 节点作为启动节点。 可以通过配置文件(配置文件)设置想要连接的节点\n\u0026lt;core.yaml\u0026gt; # Gossip related configuration gossip: # Bootstrap set to initialize gossip with bootstrap: 127.0.0.1:7051 节点启动创建用于广播的服务 initGossipService(), 除了一些常见的监听端口操作外， 会调用connect2BootstrapPeers 与配置文件定义的节点相连\n// 保留主要逻辑 func (g *Node) connect2BootstrapPeers() { for _, endpoint := range g.conf.BootstrapPeers { // 用于标记节点，声明 pk \tidentifier := func() (*discovery.PeerIdentification, error) { ... } g.disc.Connect(discovery.NetworkMember{ InternalEndpoint: endpoint, Endpoint: endpoint, }, identifier) } } func (d *gossipDiscoveryImpl) Connect(member NetworkMember, id identifier) { go func() { for i := 0; i \u0026lt; d.maxConnectionAttempts \u0026amp;\u0026amp; !d.toDie(); i++ { ... peer := \u0026amp;NetworkMember{ InternalEndpoint: member.InternalEndpoint, Endpoint: member.Endpoint, PKIid: id.ID, } // 创建 MembershipRequest, 用与向连接节点请求已知的节点，按道理来说需要发送自己的节点避免重复，但是这里fabric为了安全暂时没有实现，  // See FAB-2570 for tracking this issue. \tm, err := d.createMembershipRequest(id.SelfOrg) ... // nil 签名  ... // 发送 MembershipRequest \tgo d.sendUntilAcked(peer, req) return } }() } // \u0026lt;------------------- server peer handle logic start -------------------\u0026gt; // 每个节点在初始化 DiscoveryService(节点发现服务) 的时候会开启一个 handleMessages 的 goroutine, 对连接层消息进行处理, 这里也有周期性测活、周期性断线重连逻辑， 也会周期性的发送心跳包（alive message更新 alive 时间） // 对于 MembershipRequest 的接收方，会对收到的消息进行响应  func (d *gossipDiscoveryImpl) handleMsgFromComm(msg protoext.ReceivedMessage) { ... // 判断是否为 MembershipRequest 消息 \tif memReq := m.GetMemReq(); memReq != nil { selfInfoGossipMsg, err := protoext.EnvelopeToGossipMessage(memReq.SelfInformation) ... // 合法性校验等  ... // 将自身感知到的网络节点发送给请求方, 包括 alive 节点与 dead 节点 \tgo d.sendMemResponse(selfInfoGossipMsg.GetAliveMsg().Membership, internalEndpoint, m.Nonce) return } } // \u0026lt;------------------- server peer handle logic end -------------------\u0026gt;  // 同样在 handleMessages 逻辑里，也有对 MembershipResponse 消息的处理逻辑 func (d *gossipDiscoveryImpl) handleMsgFromComm(msg protoext.ReceivedMessage) { ... // 判断是否为 MembershipResponse 消息 \tif memResp := m.GetMemRes(); memResp != nil { for _, env := range memResp.Alive { am, err := protoext.EnvelopeToGossipMessage(env) if d.msgStore.CheckValid(am) \u0026amp;\u0026amp; d.crypt.ValidateAliveMsg(am) { // 处理 alive peer, 根据 am 时间戳更新 id2Member(map, 可以理解为通讯录)  // 1. 若之前不存在，更新  // - learnNewMembers， 记录该节点信息到 aliveLastTS、deadLastTS、id2Member等  // 2. 若之前存在，根据是否失活与本地连接时间戳对比进行决定是否更新 \td.handleAliveMessage(am) } } for _, env := range memResp.Dead { dm, err := protoext.EnvelopeToGossipMessage(env) // Newer alive message exists or the message isn\u0026#39;t authentic \tif !d.msgStore.CheckValid(dm) || !d.crypt.ValidateAliveMsg(dm) { continue } newDeadMembers := []*protoext.SignedGossipMessage{} d.lock.RLock() if _, known := d.id2Member[string(dm.GetAliveMsg().Membership.PkiId)]; !known { newDeadMembers = append(newDeadMembers, dm) } d.lock.RUnlock() d.learnNewMembers([]*protoext.SignedGossipMessage{}, newDeadMembers) } } } 此外，节点也会根据与 AnchorPeers 交换 membership 信息： 当节点加入channel时，会连接 anchor peer， 处理逻辑同connect （本质是transaction，系统合约调用/invoke） 。\n节点件消息传播 (Gossip)  消息发送方式：\n 点对点发送（end to end） gossip方式——发送消息时会根据消息类型对节点进行过滤筛选（另外还会去除掉发送节点）后再随机（具体实现上是随机就近原则）选择k个节点发送消息。这里采用的是push和pull方式。    push 节点有了新消息后，随机选择 k 个节点（例如，3），向它们发送新消息。k个节点收到后，继续随机选择k个节点发送新信息，直到所有节点都知道该新信息。  // Gossip sends a message to other peers to the network func (g *Node) Gossip(msg *pg.GossipMessage) { ... // 判断是否只在 channel 内转发 \tif protoext.IsChannelRestricted(msg) { gc := g.chanState.getGossipChannelByChainID(msg.Channel) if gc == nil { g.logger.Warning(\u0026#34;Failed obtaining gossipChannel of\u0026#34;, msg.Channel, \u0026#34;aborting\u0026#34;) return } if protoext.IsDataMsg(msg) { gc.AddToMsgStore(sMsg) } } ... // 将消息添加到batchingEmitter中，并定期(默认10ms)将它们分批转发 T 次，然后丢弃。  // 如果batchingEmitter的已存储消息计数达到/一定容量(默认是1)，则也会触发消息分发 =\u0026gt; emit() \tg.emitter.Add(\u0026amp;emittedGossipMessage{ SignedGossipMessage: sMsg, filter: func(_ common.PKIidType) bool { return true }, }) } func (p *batchingEmitterImpl) emit() { ... msgs2beEmitted := make([]interface{}, len(p.buff)) for i, v := range p.buff { msgs2beEmitted[i] = v.data } // cb =\u0026gt; gossipBatch \tp.cb(msgs2beEmitted) p.decrementCounters() } // 根据消息的不同路由策略，将消息发送到同一 peer 组，提高效率. func (g *Node) gossipBatch(msgs []*emittedGossipMessage) { ... var blocks []*emittedGossipMessage var stateInfoMsgs []*emittedGossipMessage var orgMsgs []*emittedGossipMessage var leadershipMsgs []*emittedGossipMessage // 区分不同类型的消息 \tisABlock := func(o interface{}) bool { return protoext.IsDataMsg(o.(*emittedGossipMessage).GossipMessage) } isAStateInfoMsg := func(o interface{}) bool { return protoext.IsStateInfoMsg(o.(*emittedGossipMessage).GossipMessage) } aliveMsgsWithNoEndpointAndInOurOrg := func(o interface{}) bool { msg := o.(*emittedGossipMessage) if !protoext.IsAliveMsg(msg.GossipMessage) { return false } member := msg.GetAliveMsg().Membership return member.Endpoint == \u0026#34;\u0026#34; \u0026amp;\u0026amp; g.IsInMyOrg(discovery.NetworkMember{PKIid: member.PkiId}) } isOrgRestricted := func(o interface{}) bool { return aliveMsgsWithNoEndpointAndInOurOrg(o) || protoext.IsOrgRestricted(o.(*emittedGossipMessage).GossipMessage) } isLeadershipMsg := func(o interface{}) bool { return protoext.IsLeadershipMsg(o.(*emittedGossipMessage).GossipMessage) } // Gossip blocks  blocks, msgs = partitionMessages(isABlock, msgs) // gossipInChan 目的就是获取消息所属的channel， 然后获取该channel的路由并发送出去。  // 1. 获取节点的 Membership  // 2. 根据消息类型选择发送到指定的节点  // 2.1 IsLeadershipMsg =\u0026gt; 发送给所有已知节点  // 2.2 Other =\u0026gt; 随机选 k 个节点发(默认是三个/rand.Perm)  // 3. 过滤节点并发送 =\u0026gt; g.comm.Send (grpc.stream.Send) \tg.gossipInChan(blocks, func(gc channel.GossipChannel) filter.RoutingFilter { return filter.CombineRoutingFilters(gc.EligibleForChannel, gc.IsMemberInChan, g.IsInMyOrg) }) // Gossip Leadership messages \tleadershipMsgs, msgs = partitionMessages(isLeadershipMsg, msgs) g.gossipInChan(leadershipMsgs, func(gc channel.GossipChannel) filter.RoutingFilter { return filter.CombineRoutingFilters(gc.EligibleForChannel, gc.IsMemberInChan, g.IsInMyOrg) }) // Gossip StateInfo messages \tstateInfoMsgs, msgs = partitionMessages(isAStateInfoMsg, msgs) for _, stateInfMsg := range stateInfoMsgs { peerSelector := g.IsInMyOrg gc := g.chanState.lookupChannelForGossipMsg(stateInfMsg.GossipMessage) if gc != nil \u0026amp;\u0026amp; g.hasExternalEndpoint(stateInfMsg.GossipMessage.GetStateInfo().PkiId) { peerSelector = gc.IsMemberInChan } peerSelector = filter.CombineRoutingFilters(peerSelector, func(member discovery.NetworkMember) bool { return stateInfMsg.filter(member.PKIid) }) peers2Send := filter.SelectPeers(g.conf.PropagatePeerNum, g.disc.GetMembership(), peerSelector) g.comm.Send(stateInfMsg.SignedGossipMessage, peers2Send...) } // Gossip messages restricted to our org \torgMsgs, msgs = partitionMessages(isOrgRestricted, msgs) peers2Send := filter.SelectPeers(g.conf.PropagatePeerNum, g.disc.GetMembership(), g.IsInMyOrg) for _, msg := range orgMsgs { g.comm.Send(msg.SignedGossipMessage, g.removeSelfLoop(msg, peers2Send)...) } // Finally, gossip the remaining messages \tfor _, msg := range msgs { if !protoext.IsAliveMsg(msg.GossipMessage) { g.logger.Error(\u0026#34;Unknown message type\u0026#34;, msg) continue } selectByOriginOrg := g.peersByOriginOrgPolicy(discovery.NetworkMember{PKIid: msg.GetAliveMsg().Membership.PkiId}) selector := filter.CombineRoutingFilters(selectByOriginOrg, func(member discovery.NetworkMember) bool { return msg.filter(member.PKIid) }) peers2Send := filter.SelectPeers(g.conf.PropagatePeerNum, g.disc.GetMembership(), selector) g.sendAndFilterSecrets(msg.SignedGossipMessage, peers2Send...) } } // 转发Forward // 节点在 GossipServer 启动的时候会调用 acceptMessages 用于消息的处理(向消息pub 注册一个包含过滤规则的sub, 从网络中获取各个节点发来的消息), 最终调用 channel.handleMessage func (g *Node) handleMessage(m protoext.ReceivedMessage) { ... msg := m.GetGossipMessage() if !g.validateMsg(m) { g.logger.Warning(\u0026#34;Message\u0026#34;, msg, \u0026#34;isn\u0026#39;t valid\u0026#34;) return } if protoext.IsChannelRestricted(msg.GossipMessage) { // 判断 channel 是否匹配 \t} else { if protoext.IsLeadershipMsg(m.GetGossipMessage().GossipMessage) { // LeadershipMsg 合法性校验 \t} } // 处理 channel message \tgc.HandleMessage(m) } return } if selectOnlyDiscoveryMessages(m) { // 连接相关的消息，合法性判断后转交给 discoverServer 处理，处理逻辑见上文 \tg.forwardDiscoveryMsg(m) } // 处理 pull 消息，稍后分析 \tif protoext.IsPullMsg(msg.GossipMessage) \u0026amp;\u0026amp; protoext.GetPullMsgType(msg.GossipMessage) == pg.PullMsgType_IDENTITY_MSG { g.certStore.handleMessage(m) } } // HandleMessage processes a message sent by a remote peer, 也会存储收到供之后使用 func (gc *gossipChannel) HandleMessage(msg protoext.ReceivedMessage) { ... // 各种检验，org id， channel id， org in channel  ... // 处理 Pull 逻辑，稍后分析  ... if protoext.IsDataMsg(m.GossipMessage) || protoext.IsStateInfoMsg(m.GossipMessage) { added := false if protoext.IsDataMsg(m.GossipMessage) { ... // 合法性验证  ... gc.Lock() added = gc.blockMsgStore.Add(msg.GetGossipMessage()) if added { gc.logger.Debugf(\u0026#34;Adding %v to the block puller\u0026#34;, msg.GetGossipMessage()) gc.blocksPuller.Add(msg.GetGossipMessage()) } gc.Unlock() } else { // StateInfoMsg verification should be handled in a layer above \t// since we don\u0026#39;t have access to the id mapper here \tadded = gc.stateInfoMsgStore.Add(msg.GetGossipMessage()) } if added { // 转发消息 \tgc.Forward(msg) // DeMultiplex to local subscribers \tgc.DeMultiplex(m) } return } ... // 处理拉取到的 block  ... if protoext.IsLeadershipMsg(m.GossipMessage) { // Handling leadership message \tadded := gc.leaderMsgStore.Add(m) if added { gc.DeMultiplex(m) } } } pull 所有节点周期性(默认4s)的随机选取 k 个（默认配置=3）个节点，向它们获取数据。Fabric中gossip协议pull操作如下：   Other peer\tInitiator O\t\u0026lt;-------- Hello \u0026lt;NONCE\u0026gt; ------------------------- O /|\\\t--------- Digest \u0026lt;[3,5,8, 10...], NONCE\u0026gt; --------\u0026gt; /|\\ |\t\u0026lt;-------- Request \u0026lt;[3,8], NONCE\u0026gt; ----------------- | / \\\t--------- Response \u0026lt;[item3, item8], NONCE\u0026gt;-------\u0026gt; / \\ orderer 广播区块到全网 排序节点只需要将区块分发给每个组织中的 leader 节点，由组织的 leader 负责分发到其他节点\n# 节点在 initGossipService() 时会 初始化 deliveryFactor，当节点加入channel时会通过 deliveryFactor 创建 deliver client func (g *GossipService) InitializeChannel(channelID string, ordererSource *orderers.ConnectionSource, store *transientstore.Store, support Support) { ... // 没有 deliveryService， 创建与 ordererSource 相连的 deliver client \tif g.deliveryService[channelID] == nil { g.deliveryService[channelID] = g.deliveryFactory.Service(g, ordererSource, g.mcs, g.serviceConfig.OrgLeader) } // Delivery service might be nil only if it was not able to get connected to the ordering service \tif g.deliveryService[channelID] != nil { // 不能同时为 true \t// 默认 true ,动态选取leader算法 \tleaderElection := g.serviceConfig.UseLeaderElection // 默认 false \tisStaticOrgLeader := g.serviceConfig.OrgLeader if leaderElection { g.leaderElection[channelID] = g.newLeaderElectionComponent(channelID, g.onStatusChangeFactory(channelID, support.Committer), g.metrics.ElectionMetrics) } else if isStaticOrgLeader { g.deliveryService[channelID].StartDeliverForChannel(channelID, support.Committer, func() {}) } ... } // 开启 Deliver For Channel func (d *deliverServiceImpl) StartDeliverForChannel(chainID string, ledgerInfo blocksprovider.LedgerInfo, finalizer func()) error { ... dc := \u0026amp;blocksprovider.Deliverer{...} ... d.blockProviders[chainID] = dc go func() { // 查询本地账本，获取seekInfo，与orderer 创建 deliverClient 发送seekInfo， 获取resp, 一顿操作后提交到本地正本，然后将其分发(gossip)到其他peer \tdc.DeliverBlocks() // Yield, 切换leader逻辑 \tfinalizer() }() return nil } "
            }
        
    
]